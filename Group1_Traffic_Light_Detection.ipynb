{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewli4938/TrafficLightDetection/blob/main/Group1_Traffic_Light_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P3N9_e8oCyxX",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c93e0a4-e765-433f-992f-d223ae9664e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.27)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WgojNACwLyeH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLFdipyYPOoK"
      },
      "outputs": [],
      "source": [
        "# import our dataset\n",
        "import kagglehub\n",
        "source_path = kagglehub.dataset_download(\"mbornoe/lisa-traffic-light-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "%rm -r data\n",
        "%mkdir data  # root folder for data\n",
        "\n",
        "%cd data\n",
        "%mkdir images\n",
        "%mkdir labels\n",
        "\n",
        "%cd images\n",
        "%mkdir train\n",
        "%mkdir val\n",
        "%mkdir test\n",
        "\n",
        "%cd ../labels\n",
        "%mkdir train\n",
        "%mkdir val\n",
        "%mkdir test\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "45n_O0TxJ3tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these two only have total 1000 images, and have duplicate filenames so we can deal with them later\n",
        "%mv {source_path}/sample-dayClip6 {source_path}/..\n",
        "%mv {source_path}/sample-nightClip1 {source_path}/.."
      ],
      "metadata": {
        "id": "_W8DxNn1ue-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move all of the filenames into list\n",
        "image_paths = glob.glob(f\"{source_path}/**/*.jpg\", recursive=True)\n",
        "\n",
        "# process the annotations\n",
        "target = \"frameAnnotationsBOX.csv\"\n",
        "annotations = pd.DataFrame()\n",
        "annotation_paths = glob.glob(f\"{source_path}/**/{target}\", recursive=True)\n",
        "for p in annotation_paths:\n",
        "  # combine the csv files into one\n",
        "  new_frame = pd.read_csv(p, sep=\";\")\n",
        "  new_frame = new_frame.drop(['Origin file', 'Origin frame number', 'Origin track', 'Origin track frame number'], axis=1)\n",
        "  annotations = pd.concat([annotations, new_frame])\n",
        "filenames = annotations[annotations.columns[0]].str.split(\"/\").str[-1]\n",
        "annotations[\"Filename\"] = filenames\n",
        "annotations.set_index(\"Filename\", inplace=True)\n",
        "annotations"
      ],
      "metadata": {
        "id": "KFip5Yv4qdxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_files(paths_list, destination_dir):\n",
        "  for file in paths_list:\n",
        "    shutil.copy(file, destination_dir)"
      ],
      "metadata": {
        "id": "LpDI_kUN0j7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: split the data into train, val, test\n",
        "image_train, image_val_test = train_test_split(image_paths, train_size=0.7, test_size=0.3, random_state=42, shuffle=True)\n",
        "image_val, image_test = train_test_split(image_val_test, train_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "print(len(image_train))\n",
        "print(len(image_val))\n",
        "print(len(image_test))\n",
        "\n",
        "image_train_dir = \"/content/data/images/train\"\n",
        "image_val_dir = \"/content/data/images/val\"\n",
        "image_test_dir = \"/content/data/images/test\"\n",
        "move_files(image_train, image_train_dir)\n",
        "move_files(image_val, image_val_dir)\n",
        "move_files(image_test, image_test_dir)\n",
        "\n",
        "print(len(os.listdir(image_train_dir)))\n",
        "print(len(os.listdir(image_val_dir)))\n",
        "print(len(os.listdir(image_test_dir)))"
      ],
      "metadata": {
        "id": "5c5NE8fJnGeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import yaml file: defines image locations and encodes classes into numbers for the model\n",
        "!wget https://raw.githubusercontent.com/andrewli4938/TrafficLightDetection/refs/heads/main/data.yaml"
      ],
      "metadata": {
        "id": "l1ERSVO7bpFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_xywh(box_coordinates, image_dimensions):\n",
        "  image_width, image_height = image_dimensions\n",
        "  x1, y1, x2, y2 = box_coordinates\n",
        "  width, height = x2-x1, y2-y1\n",
        "  x_center = (x1+x2)/2\n",
        "  y_center = (y1+y2)/2\n",
        "\n",
        "  x_center = x_center/image_width\n",
        "  y_center = y_center/image_height\n",
        "  width = width/image_width\n",
        "  height = height/image_height\n",
        "\n",
        "  return (x_center, y_center, width, height)"
      ],
      "metadata": {
        "id": "u9Ep7b_kr-IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The *.txt file should be formatted with one row per object in\n",
        "class x_center y_center width height format. Box coordinates\n",
        "must be in normalized xywh format (from 0 to 1). If your boxes\n",
        "are in pixels, you should divide x_center and width by image width,\n",
        "and y_center and height by image height. Class numbers should be\n",
        "zero-indexed (start with 0).\n",
        "\"\"\"\n",
        "image_dims = (1280, 960)\n",
        "\n",
        "def create_labels(source_dir, destination_dir, annotations_df, encoding):\n",
        "  bounding_box_df = annotations_df.iloc[:, 1:]\n",
        "  for file in os.listdir(source_dir):\n",
        "    write_path = os.path.join(destination_dir, file.replace(\".jpg\", \".txt\"))\n",
        "    if file in annotations_df.index:\n",
        "      rows = annotations_df.loc[file]\n",
        "      if isinstance(rows, pd.Series):\n",
        "        rows = pd.DataFrame([rows])\n",
        "    else:\n",
        "      continue\n",
        "    with open(write_path, \"w\") as image_label:\n",
        "      for i in range(len(rows)):  # iterate through each label for current image\n",
        "        class_number = encoding[rows.iloc[i, 0]]\n",
        "        bounding_box = bounding_box_df.iloc[i]\n",
        "        # print(bounding_box)\n",
        "        # print(f\"image is: {file} at index {i}\")\n",
        "        # print(type(rows))\n",
        "        xywh = convert_to_xywh(bounding_box, image_dims)  # calculate bounding box coordinates here\n",
        "        image_label.write(f\"{class_number} {xywh[0]} {xywh[1]} {xywh[2]} {xywh[3]}\\n\")\n"
      ],
      "metadata": {
        "id": "3NBCBSrbARB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_encoding = {\"stop\": 0, \"stopLeft\": 1, \"warning\": 2, \"warningLeft\": 3,\n",
        "                  \"warningLeft\": 4, \"go\": 5, \"goForward\": 6, \"goLeft\": 6}\n",
        "\n",
        "label_train_dir = \"/content/data/labels/train\"\n",
        "label_val_dir = \"/content/data/labels/val\"\n",
        "label_test_dir = \"/content/data/labels/test\"\n",
        "\n",
        "create_labels(image_train_dir, label_train_dir, annotations, class_encoding)\n",
        "create_labels(image_val_dir, label_val_dir, annotations, class_encoding)\n",
        "create_labels(image_test_dir, label_test_dir, annotations, class_encoding)\n",
        "\n",
        "print(len(os.listdir(label_train_dir)))\n",
        "print(len(os.listdir(label_val_dir)))\n",
        "print(len(os.listdir(label_test_dir)))"
      ],
      "metadata": {
        "id": "fBfjtqMuxhlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "6pAu7cwTNMuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b9b7ad-6289-427a-89b9-ce0b7833f809"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_ryn_szsW4O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuuR89vuXVWe",
        "outputId": "e811f1b8-6995-449d-a47d-2c20a13917aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  5 03:36:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   50C    P8              13W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/runs"
      ],
      "metadata": {
        "id": "LZARy5ZBU8QX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "results = model.train(data=\"/content/data.yaml\", epochs=40, imgsz=896, batch=64)"
      ],
      "metadata": {
        "id": "9IvkBF_T6K2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748be721-a383-40ce-931f-30b6331dc6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 64.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.27 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/data.yaml, epochs=40, time=None, patience=100, batch=64, imgsz=896, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "YOLO11n summary: 319 layers, 2,591,205 parameters, 2,591,189 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train.cache... 25473 images, 4638 backgrounds, 0 corrupt: 100%|██████████| 30111/30111 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val.cache... 5412 images, 1040 backgrounds, 0 corrupt: 100%|██████████| 6452/6452 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 896 train, 896 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/40      18.4G      3.522      10.25      1.191         84        896: 100%|██████████| 471/471 [08:53<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.619      0.125     0.0654     0.0211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/40      18.4G      2.859      3.292      1.015        118        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:48<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.583     0.0425     0.0506     0.0209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/40      18.4G      2.605      2.403     0.9839         99        896: 100%|██████████| 471/471 [08:53<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:47<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295       0.63    0.00574    0.00955    0.00256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/40      18.4G      2.453      2.181     0.9652        124        896: 100%|██████████| 471/471 [08:53<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.753      0.206      0.211      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/40      18.4G      2.204      1.863       0.93         85        896: 100%|██████████| 471/471 [08:52<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.703      0.206      0.238      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/40      18.4G      2.085      1.746     0.9166        149        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.834       0.22      0.285      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/40      18.4G      1.942      1.616     0.9003        113        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.827      0.218      0.294      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/40      18.4G      1.848      1.533     0.8903        111        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295       0.61      0.305      0.332      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/40      18.4G      1.773      1.463     0.8804        100        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.651      0.287      0.334      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/40      18.5G      1.718      1.422     0.8744        135        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:52<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.649      0.406      0.435      0.291\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/40      18.4G      1.663      1.375     0.8676        135        896: 100%|██████████| 471/471 [08:49<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.793      0.312      0.411      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/40      18.2G       1.61       1.34     0.8629        141        896: 100%|██████████| 471/471 [08:49<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:48<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.534      0.461      0.471      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/40      18.4G       1.57      1.309     0.8591        112        896: 100%|██████████| 471/471 [08:52<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.598      0.455      0.508      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/40      18.5G      1.523      1.275     0.8536         78        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.627      0.477       0.52      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/40      18.4G      1.499      1.253     0.8511        129        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.547      0.524      0.536      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/40      18.2G      1.468      1.229     0.8494        116        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.608      0.544       0.57      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/40      18.4G      1.438      1.203     0.8455        100        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295       0.67      0.528      0.594      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/40      18.4G      1.412      1.185     0.8438        113        896: 100%|██████████| 471/471 [08:52<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.624      0.565      0.605      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/40      18.3G      1.382      1.161     0.8405        104        896: 100%|██████████| 471/471 [08:53<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.696      0.567      0.632      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/40      18.3G       1.36      1.143     0.8383        145        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.703      0.604       0.66      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/40      18.4G      1.341      1.132     0.8371        117        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.764      0.588      0.675        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/40      18.4G      1.308      1.101     0.8332        106        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.754      0.602      0.688      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/40      18.4G      1.284      1.079     0.8325        110        896: 100%|██████████| 471/471 [08:53<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.746      0.636      0.705      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/40      18.2G      1.261      1.059     0.8291        120        896: 100%|██████████| 471/471 [08:50<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.807      0.613      0.708      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/40      18.4G      1.236      1.035     0.8271        120        896: 100%|██████████| 471/471 [08:48<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.788      0.638      0.721      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/40      18.3G      1.228      1.024     0.8263         89        896: 100%|██████████| 471/471 [08:52<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.786       0.65      0.732       0.57\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/40      18.5G      1.198      1.007     0.8247        144        896: 100%|██████████| 471/471 [08:53<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:51<00:00,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.795      0.652      0.736      0.568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/40      18.3G      1.182     0.9941     0.8234        137        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.808      0.646       0.75      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/40      18.4G      1.161     0.9777      0.823        129        896: 100%|██████████| 471/471 [08:54<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.793      0.674      0.759      0.595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/40      18.3G      1.135     0.9626     0.8212        130        896: 100%|██████████| 471/471 [08:51<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:51<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.811      0.676      0.768      0.602\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/40        19G      1.106     0.8784     0.8201         62        896: 100%|██████████| 471/471 [08:36<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.821      0.677      0.775       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/40      18.2G      1.042     0.8274     0.8147         55        896: 100%|██████████| 471/471 [08:27<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:51<00:00,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.834      0.674      0.781      0.619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/40      18.2G      1.004     0.7999     0.8137         56        896: 100%|██████████| 471/471 [08:27<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.811      0.693      0.789      0.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/40      18.3G     0.9593     0.7722     0.8094         48        896: 100%|██████████| 471/471 [08:28<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.796      0.711      0.797      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/40      18.2G     0.9348     0.7574     0.8084         64        896: 100%|██████████| 471/471 [08:27<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:49<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.816      0.708      0.803      0.647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/40      18.2G     0.8986      0.738     0.8062         54        896: 100%|██████████| 471/471 [08:25<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.813      0.717      0.808      0.655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/40      18.2G      0.872     0.7196     0.8047         72        896: 100%|██████████| 471/471 [08:27<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.818       0.72      0.812      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/40      18.2G     0.8343     0.6999     0.8046         56        896: 100%|██████████| 471/471 [08:27<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:51<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.819      0.724      0.815      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/40      18.2G     0.8015     0.6836     0.8025         60        896: 100%|██████████| 471/471 [08:28<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295       0.82      0.725      0.821      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/40      18.2G     0.7676     0.6597     0.8002         57        896: 100%|██████████| 471/471 [08:28<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:50<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.824      0.723      0.824      0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "40 epochs completed in 6.423 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.27 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,583,517 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   2%|▏         | 1/51 [00:01<00:50,  1.00s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_model = YOLO('/content/runs/detect/train/weights/last.pt')\n",
        "result = val_model.val(data='/content/data.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dS8Hul1y7gu",
        "outputId": "b759dd7d-bec3-46cb-80b4-3104f2f2b507"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.27 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,583,517 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val.cache... 5412 images, 1040 backgrounds, 0 corrupt: 100%|██████████| 6452/6452 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 404/404 [00:56<00:00,  7.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       6452      16295      0.824      0.723      0.824      0.728\n",
            "                  stop       2792       6704      0.899       0.94      0.974      0.891\n",
            "              stopLeft       1562       1918      0.873      0.828      0.922      0.834\n",
            "               warning        150        344      0.817      0.776      0.856      0.765\n",
            "                    go         39         57      0.696      0.298       0.51      0.409\n",
            "             goForward       2780       6903       0.89      0.949      0.975      0.889\n",
            "                goLeft        276        369      0.769      0.549      0.705      0.577\n",
            "Speed: 0.4ms preprocess, 2.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.results_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFze3vMr0vBh",
        "outputId": "4e46fe76-4f78-4526-a4e9-b2116db7904a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metrics/precision(B)': 0.8239254840899588,\n",
              " 'metrics/recall(B)': 0.7234864557570194,\n",
              " 'metrics/mAP50(B)': 0.8237260585905727,\n",
              " 'metrics/mAP50-95(B)': 0.7276078642319429,\n",
              " 'fitness': 0.7372196836678059}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: the label files are producing duplicate files, fix the create_labels() function"
      ],
      "metadata": {
        "id": "qXf60zCVGvjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "OVERVIEW\n",
        "Basically our LISA dataset contains around 44k images and a bunch of labels\n",
        "\n",
        "Labels are:\n",
        "  - light status: {go, slow, stop}\n",
        "  - bounding box of where the stoplight is xyxy coordinates (top left, bottom right)\n",
        "  - each image may have many labels since there are many stoplights in a single image\n",
        "\n",
        "DaySequence\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HQB7win5OQJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "END HERE\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dba5MRpjJyWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwQVJqBrkSHd",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# # centralize both annotations and images (not scattered in different folders)\n",
        "# annotations = pd.DataFrame()\n",
        "\n",
        "# target = \"frameAnnotationsBOX.csv\"\n",
        "# annotation_paths = glob.glob(f\"{path}/**/{target}\", recursive=True)\n",
        "\n",
        "# # I am going to omit the approximately 1000 pictures and labels in sample-dayClip6\n",
        "# # and sample-nightClip1 because it is really annoying to work with right now and and\n",
        "# # we have 43k other values we can work with first\n",
        "# for p in annotation_paths:\n",
        "#   tokens = p.split(\"/\")\n",
        "#   if tokens[-2] == \"sample-nightClip1\" or tokens[-2] == \"sample-dayClip6\":  # omit here\n",
        "#     continue\n",
        "\n",
        "#   # combine the csv files into one\n",
        "#   new_frame = pd.read_csv(p, sep=\";\")\n",
        "#   new_frame = new_frame.drop(['Origin file', 'Origin frame number', 'Origin track', 'Origin track frame number'], axis=1)\n",
        "#   annotations = pd.concat([annotations, new_frame])\n",
        "\n",
        "#   # move all of the nested image files into /content/images_dir\n",
        "#   if len(tokens)==14:\n",
        "#     subpath = path+\"/\"+tokens[-3]+\"/\"+tokens[-3]+\"/\"+tokens[-2]+\"/frames\"\n",
        "#   else:\n",
        "#     subpath = path+\"/\"+tokens[-2]+\"/\"+tokens[-2]+\"/frames\"\n",
        "#   !cp -r {subpath}/* /content/images_dir\n",
        "\n",
        "# filenames = annotations[annotations.columns[0]].str.split(\"/\").str[-1]\n",
        "# annotations[\"Filename\"] = filenames\n",
        "# annotations  # NOTE: our labels are in this df here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgbdVBPcdR3r"
      },
      "outputs": [],
      "source": [
        "# #TODO: define custom dataset class\n",
        "# class TrafficLightDataset(Dataset):\n",
        "#   def __init__(self, annotations_df, img_dir, transform=None, target_transform=None):\n",
        "#     self.img_labels = annotations_df\n",
        "#     self.img_dir = img_dir\n",
        "#     self.transform = transform\n",
        "#     self.target_transform = target_transform\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.img_labels)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "#     image = read_image(img_path)\n",
        "#     label = tuple(self.img_labels.iloc[idx, 1:])\n",
        "#     if self.transform:\n",
        "#       image = self.transform(image)\n",
        "#     if self.target_transform:\n",
        "#       pass  # not sure how this will work on a tuple (worry about it later)\n",
        "#     return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8t3uUaoUrOd"
      },
      "outputs": [],
      "source": [
        "# #TODO: split our data into train and test dataloaders\n",
        "\n",
        "# img_dir = \"content/images_dir\"\n",
        "# dataset = TrafficLightDataset(annotations, img_dir, transform=None, target_transform=None)\n",
        "\n",
        "# # shuffle our indices before splitting (need day and night in both sets)\n",
        "# indices = torch.randperm(len(dataset))\n",
        "# train_size = int(0.8*len(dataset))\n",
        "# train_indices = indices[:train_size]\n",
        "# test_indices = indices[train_size:]\n",
        "\n",
        "# # split into train and test\n",
        "# train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "# test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "# # we have our dataloaders here\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size=1000, shuffle=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}